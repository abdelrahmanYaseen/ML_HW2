{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_original.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "0       1       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       1       0   \n",
       "2       0       0       0       0       0       0       0       1       0   \n",
       "3       1       0       0       1       6       1       5       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   feat_10  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0        0  ...        1        0        0        0        0        0   \n",
       "1        0  ...        0        0        0        0        0        0   \n",
       "2        0  ...        0        0        0        0        0        0   \n",
       "3        1  ...        0        1        2        0        0        0   \n",
       "4        0  ...        1        0        0        0        0        1   \n",
       "\n",
       "   feat_91  feat_92  feat_93   target  \n",
       "0        0        0        0  Class_1  \n",
       "1        0        0        0  Class_1  \n",
       "2        0        0        0  Class_1  \n",
       "3        0        0        0  Class_1  \n",
       "4        0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoded = data_df.copy()\n",
    "LE = LabelEncoder()\n",
    "LE.fit(data_df.target.unique()) #fit the classes names\n",
    "data_encoded.target = LE.transform(data_df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the next step (normalization) I have to separate the labels column from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_encoded.iloc[:,0:len(data_encoded.columns)-1]\n",
    "X = X.astype(float)\n",
    "Y = data_encoded.iloc[:,len(data_encoded.columns)-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>0.149647</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.402093</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>0.079240</td>\n",
       "      <td>13.508710</td>\n",
       "      <td>4.524667</td>\n",
       "      <td>4.665884</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>0.679472</td>\n",
       "      <td>...</td>\n",
       "      <td>19.044887</td>\n",
       "      <td>-0.280099</td>\n",
       "      <td>-0.047949</td>\n",
       "      <td>1.019683</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>-0.176699</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.210106</td>\n",
       "      <td>-0.307165</td>\n",
       "      <td>-0.279443</td>\n",
       "      <td>-0.161867</td>\n",
       "      <td>-0.119331</td>\n",
       "      <td>-0.188045</td>\n",
       "      <td>-0.293664</td>\n",
       "      <td>-0.291038</td>\n",
       "      <td>-0.243606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061446</td>\n",
       "      <td>0.246100</td>\n",
       "      <td>-0.420870</td>\n",
       "      <td>-0.249802</td>\n",
       "      <td>-0.413584</td>\n",
       "      <td>-0.299712</td>\n",
       "      <td>0.040798</td>\n",
       "      <td>-0.129516</td>\n",
       "      <td>-0.386938</td>\n",
       "      <td>-0.104963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3          4         5         6   \\\n",
       "0  0.402093 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "1 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "2 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "3  0.402093 -0.210106 -0.307165  0.079240  13.508710  4.524667  4.665884   \n",
       "4 -0.253508 -0.210106 -0.307165 -0.279443  -0.161867 -0.119331 -0.188045   \n",
       "\n",
       "         7         8         9   ...         83        84        85        86  \\\n",
       "0 -0.293664 -0.291038 -0.243606  ...  -0.061446  0.246100 -0.420870 -0.249802   \n",
       "1  0.149647 -0.291038 -0.243606  ...  -0.061446 -0.280099 -0.420870 -0.249802   \n",
       "2  0.149647 -0.291038 -0.243606  ...  -0.061446 -0.280099 -0.420870 -0.249802   \n",
       "3 -0.293664 -0.291038  0.679472  ...  19.044887 -0.280099 -0.047949  1.019683   \n",
       "4 -0.293664 -0.291038 -0.243606  ...  -0.061446  0.246100 -0.420870 -0.249802   \n",
       "\n",
       "         87        88        89        90        91        92  \n",
       "0 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963  \n",
       "1 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963  \n",
       "2 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963  \n",
       "3 -0.413584 -0.299712 -0.176699 -0.129516 -0.386938 -0.104963  \n",
       "4 -0.413584 -0.299712  0.040798 -0.129516 -0.386938 -0.104963  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled=pd.DataFrame(scaler.transform(X))\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30939,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=42)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shooting in the dark\n",
    "First, I'll brute-force search through the most famous classifiers  and see which ones perform the best. Then I'm planning to pick the best 3 and try to enhance their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.757199 (0.006020)\n",
      "LDA: 0.700766 (0.005116)\n",
      "KNN: 0.752222 (0.001559)\n",
      "CART: 0.675199 (0.003016)\n",
      "NB: 0.561720 (0.045236)\n",
      "SVM: 0.753418 (0.004113)\n",
      "RF: 0.777433 (0.003821)\n",
      "ADA: 0.679143 (0.002952)\n",
      "EXT: 0.780956 (0.003272)\n",
      "GB: 0.761692 (0.004694)\n",
      "XGB: 0.763922 (0.004403)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHCRJREFUeJzt3X2cnGV97/HP12AAUWG3CQJ5RA0UjmI4rGAFBKpgjm0Bq4VETk14qfhQpGKlQvWYBVtNe6r4FFspL0RqQ6C8BIOVAj2IgkXJRiOQ8JSEhyyRGtiFSAkPCb/zx30t3JnM7M7uzO7M7vV9v17z2rmf5rqu2ZnvXPd133OPIgIzM8vDy1pdATMzGzsOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0bVgkXSrpr0fpsU+TdMMgy4+V1DsaZY93kv5K0sWtroe1P4e+VSXpZkn9knYdqzIj4l8i4oRSHULS68eqfBXOknSXpP+W1CvpXyW9cazqMFIR8YWI+GCr62Htz6FvO5E0GzgaCODEMSpzl7EoZwhfBf4cOAvoBA4ArgH+oJWVGkqbPHc2Tjj0rZr3Az8DLgUWDraipL+U9GtJmyR9sNw7l7SnpMskbZb0kKTPSnpZWrZI0k8lXSipD+hO825Ny3+SiviVpKcknVoq8y8k/SaVe3pp/qWSvinpurTNTyXtI+kraa/lHkmH1mjHHODPgAURcVNEPBsRT6e9jyXDbM8TkjZIemuavzHVd2FFXf9R0o2Sfivpx5JmlZZ/NW23RdIqSUeXlnVLukrSdyVtARaled9Ny3dLyx5PdVkp6TVp2X6SVkjqk7RO0ocqHvfK1MbfSlojqWuw/7+NPw59q+b9wL+k2zsHAqOSpHnAJ4F3AK8HjqlY5evAnsBr07L3A6eXlh8BbAD2Bv6mvGFEvC3dfVNEvDIirkjT+6THnAZ8AFgqqaO06SnAZ4EpwLPAbcAv0vRVwJdrtPntQG9E3F5jeb3tuQP4HWAZsBx4M8Vz87+Bb0h6ZWn904DPp7qtpni+B6wE5lLscSwD/lXSbqXlJ6X27FWxHRQf1HsCM1JdPgJsTcsuB3qB/YD3Al+Q9PbStiemeu8FrAC+McjzYeOQQ992IOkoYBZwZUSsAtYD76ux+inAtyNiTUQ8DZxfepxJwKnAeRHx24h4EPgS8Kel7TdFxNcjYltEbKU+zwMXRMTzEfFD4CngwNLyqyNiVUQ8A1wNPBMRl0XEduAKoGpPnyIcf12r0Drb80BEfLtU1oxU12cj4gbgOYoPgAH/FhE/iYhngc8AvydpBkBEfDciHk/PzZeAXSvaeVtEXBMRL1R57p5P7Xl9RGxPz8eW9NhHAZ+OiGciYjVwcUUbbo2IH6Y2/DPwplrPiY1PDn2rtBC4ISIeS9PLqD3Esx+wsTRdvj8FmAw8VJr3EEUPvdr69Xo8IraVpp8Gyr3n/yrd31plurzuDo8L7DtIufW0p7IsImKw8l9sf0Q8BfRRPKcDQ1h3S3pS0hMUPfcp1bat4p+B64Hladjt7yS9PD12X0T8dpA2PFq6/zSwm48ZTCwOfXuRpN0peu/HSHpU0qPA2cCbJFXr8f0amF6anlG6/xhFj3NWad5M4JHSdDtd4vX/AdMHGcOupz3D9eLzlYZ9OoFNafz+0xT/i46I2At4ElBp25rPXdoLOj8iDgbeCvwhxVDUJqBT0qua2AYbZxz6VnYysB04mGI8eS5wEHALRWhUuhI4XdJBkl4BfG5gQRoeuBL4G0mvSgcpPwl8dxj1+S+K8fNRFxH3A98ELlfxfYDJ6YDofEnnNqk9ld4l6ShJkynG9n8eERuBVwHbgM3ALpI+B7y63geVdJykN6YhqS0UH1bb02P/J/DF1LZDKI6LVB4TsAnMoW9lCynG6B+OiEcHbhQH806r3M2PiOuArwE/AtZRHDSF4gAqwMeB/6Y4WHsrxVDRJcOoTzfwnXQGyikjbNNwnEXR1qXAExTHM94NXJuWN9qeSsuAxRTDOodRHNiFYmjmOuA+iuGXZxjeUNg+FAd5twB3Az/mpQ+nBcBsil7/1cDiiLixgTbYOCP/iIo1i6SDgLuAXSvG3a2CpEspzhb6bKvrYnlxT98aIundaSikA/hb4FoHvln7cuhboz5MMfa8nuJ4wEdbWx0zG4yHd8zMMuKevplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZabtfuZ8yZUrMnj271dUwMxtXVq1a9VhETB1qvbYL/dmzZ9PT09PqapiZjSuSHqpnPQ/vmJllxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGWm7L2eZWZ4kDblORIxBTSY29/TNrGU6OzuRVFfgAy+uK4nOzs5Rrt3E5J6+WRvKpdfb398/4nbU+0FhO3Lom7WhyiCUNCFCvlIsfjV07znybW3YHPpmbaKzs5P+/v6aywfr2XZ0dNDX1zca1RpVOn/LiLft6Oigr7t5dcmFQ9+sTfSdtR0Yae91ezOrMmbKey+5DGm1mkPfrE3o/C0NjW9Hd3PrM9Yc6GPDoW/WRkZ6cLKjo6PJNbGJyqFv1iY81GFjwaFv1oYc6DZa/OUsM7OMOPTNzDLi4R0zsxZpxbEbh76ZZW+o8B2tYyyt+Oa1h3fMLHsRscOtcl6zlC8wV+0GDLq8GReZc0/fzLIz1CUvoHbvv5FLXjT2rWtoxjevx33ot2q3zMzGr1Zd3bORb10PlN3oN6/HfejncjVCM2ueVl7ds5EPjWZ883rchX6rdsvMbOJo1XWOqnVSh7tNo8Zd6PtHF8ysGdrhOketGJUYd6HvH12wseRr4ExMw+1xT6T/8bgL/dwvP2ujq57hw0oDgeHhw/FrIoX6UOoKfUnzgK8Ck4CLI2JJxfILgePS5CuAvSNir7RsO3BnWvZwRJzYaKXbYbfMJiYPH9pEN2ToS5oELAWOB3qBlZJWRMTagXUi4uzS+h8HDi09xNaImNusCg/1hpyIZ++MpPc5wL3P4fHwoU109fT0DwfWRcQGAEnLgZOAtTXWXwAsbk71DPL8Gb1W8fChTXT1hP40YGNpuhc4otqKkmYB+wM3lWbvJqkH2AYsiYhrRljXqqrtUpfnTYhef/eTO0zmdNCpFTx8aBNZPaFf7R1QK1XmA1dFRLl7OTMiNkl6LXCTpDsjYv0OBUhnAGcAzJw5s44qlSqSYcDl2Oax0g7nUZuNpnouuNYLzChNTwc21Vh3PnB5eUZEbEp/NwA3s+N4/8A6F0VEV0R0TZ06tY4qmY2NygtxVbuZjSf1hP5KYI6k/SVNpgj2FZUrSToQ6ABuK83rkLRruj8FOJLaxwLMzGyUDTm8ExHbJJ0JXE9xyuYlEbFG0gVAT0QMfAAsAJbHjl2fg4BvSXqB4gNmSfmsHzMzG1tqt93Trq6u6OnpaXU1zMzGFUmrIqJrqPX8IypmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkV1aXYHxStKQ60TEGNTEzKx+dfX0Jc2TdK+kdZLOrbL8Qkmr0+0+SU+Uli2UdH+6LWxm5VspIna41ZpnZtZOhuzpS5oELAWOB3qBlZJWRMTagXUi4uzS+h8HDk33O4HFQBcQwKq0bX9TWzEGOjs76e8fvNqD9f47Ojro6+trdrXMzIalnp7+4cC6iNgQEc8By4GTBll/AXB5uv9O4MaI6EtBfyMwr5EKt0p/f/9OPfnh3Ib6wDAzGwv1jOlPAzaWpnuBI6qtKGkWsD9w0yDbTquy3RnAGQAzZ86so0pjLxa/Grr3bGx7M7MWqyf0q41Z1Bqwng9cFRHbh7NtRFwEXATQ1dXVloPhOn9LQ+P0koju5tXHzGwk6hne6QVmlKanA5tqrDufl4Z2hrtt25M04ltHR0erq29mVlforwTmSNpf0mSKYF9RuZKkA4EO4LbS7OuBEyR1SOoATkjzxp2hxuyHWscHcc2sHQw5vBMR2ySdSRHWk4BLImKNpAuAnogY+ABYACyP0hhIRPRJ+jzFBwfABRExIdKv2pk6lfN82qaZtRu1WzB1dXVFT09Pq6thZjauSFoVEV1DrefLMJiZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhnxL2eZ2Q78q3ATm3v6Zpnr7Ozc4eKA9RhYt7Ozc5RrZ83mnr5Z5vrO2g6M9Pcetg+9irUVh77Vzbv9E5PO3zLibTs6Oujrbl5dbPR5eMdqamS337v+40e1y4TXu40vGT7+uKdvNTW22w/e9R+fvLc2sTn0raZGdvvBu/5m7cihbzVV9vg8pm82/jn0rW4OdLPxzwdyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCN1hb6keZLulbRO0rk11jlF0lpJayQtK83fLml1uq1oVsXNzGz4hrzgmqRJwFLgeKAXWClpRUSsLa0zBzgPODIi+iXtXXqIrRExt8n1NjOzEainp384sC4iNkTEc8By4KSKdT4ELI2IfoCI+E1zq2lmZs1QT+hPAzaWpnvTvLIDgAMk/VTSzyTNKy3bTVJPmn9ytQIknZHW6dm8efOwGmBmZvWr53r61X45o/LC6rsAc4BjgenALZLeEBFPADMjYpOk1wI3SbozItbv8GARFwEXAXR1dfmi7WZmo6Senn4vMKM0PR3YVGWd70fE8xHxAHAvxYcAEbEp/d0A3Awc2mCdzcxshOoJ/ZXAHEn7S5oMzAcqz8K5BjgOQNIUiuGeDZI6JO1amn8ksBYzM2uJIYd3ImKbpDOB64FJwCURsUbSBUBPRKxIy06QtBbYDpwTEY9LeivwLUkvUHzALCmf9WNmZmNL7fa7p11dXdHT09PqapiZjSuSVkVE11Dr+Ru5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWVkl1ZXwKwekgZdHhFjVBOz8c2hb+NCOdQlOeTNRqiu4R1J8yTdK2mdpHNrrHOKpLWS1khaVpq/UNL96bawWRU3M7PhG7KnL2kSsBQ4HugFVkpaERFrS+vMAc4DjoyIfkl7p/mdwGKgCwhgVdq2v/lNMTOzodTT0z8cWBcRGyLiOWA5cFLFOh8Clg6EeUT8Js1/J3BjRPSlZTcC85pTdTMzG656Qn8asLE03ZvmlR0AHCDpp5J+JmneMLZF0hmSeiT1bN68uf7am5nZsNQT+tVOm6g8irYLMAc4FlgAXCxprzq3JSIuioiuiOiaOnVqHVUyM7ORqCf0e4EZpenpwKYq63w/Ip6PiAeAeyk+BOrZ1szMxkg9ob8SmCNpf0mTgfnAiop1rgGOA5A0hWK4ZwNwPXCCpA5JHcAJaZ6ZmbXAkGfvRMQ2SWdShPUk4JKIWCPpAqAnIlbwUrivBbYD50TE4wCSPk/xwQFwQUT0jUZDzMxsaGq3L7l0dXVFT09Pq6thbcxfzjLbmaRVEdE11Hq+9o6ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHoW1vq7OxEUtUbUHOZJDo7O1tce7P25R9RsbbU398/4nPxh/qVLbOcuadvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGfH19K0txeJXQ/eeI9/WzKpy6Ftb0vlbGvoRlehubn3MJgoP75iZZcShb2aWEYe+mVlG6gp9SfMk3StpnaRzqyxfJGmzpNXp9sHSsu2l+SuaWXkzMxueIQ/kSpoELAWOB3qBlZJWRMTailWviIgzqzzE1oiY23hVzcysUfX09A8H1kXEhoh4DlgOnDS61TIzs9FQT+hPAzaWpnvTvErvkXSHpKskzSjN301Sj6SfSTq5WgGSzkjr9GzevLn+2puZ2bDUE/qqMq/yBOprgdkRcQjwH8B3SstmRkQX8D7gK5Jet9ODRVwUEV0R0TV16tQ6q25mZsNVT+j3AuWe+3RgU3mFiHg8Ip5Nk/8EHFZatin93QDcDBzaQH3NzKwB9YT+SmCOpP0lTQbmAzuchSNp39LkicDdaX6HpF3T/SnAkUDlAWAzMxsjQ569ExHbJJ0JXA9MAi6JiDWSLgB6ImIFcJakE4FtQB+wKG1+EPAtSS9QfMAsqXLWj5mZjRGN9Pomo6Wrqyt6enpaXQ1rMUmNXXunzV7XZqNN0qp0/HRQ/kaumVlGHPpmZhnxpZWtbUnVzhYeWkdHR5NrYjZxOPStLQ02Ju8xe7OR8/COmVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcTX07dxofIHVSqnfX19s/o49G1ccKibNYeHd8zMMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4yo3b70Imkz8FADDzEFeKxJ1RkP5bay7NzKbWXZbnMeZTdS7qyImDrUSm0X+o2S1BMRXbmU28qycyu3lWW7zXmUPRblenjHzCwjDn0zs4xMxNC/KLNyW1l2buW2smy3OY+yR73cCTemb2ZmtU3Enr6ZmdUwbkNf0lNV5nVLekTSaklrJS0Yo7Lul/Q9SQdXrDNV0vOSPtxouZLelcqZmcp+WtLeNdYNSV8qTX9KUncd5e0jabmk9en5+6GkA9KysyU9I2nP0vrHSnpS0i8l3SPp79P809PzslrSc5LuTPeXDLP9NdtR8fzfI+kfJDX0epb0GUlrJN2RHvc6SV+sWGeupLvT/Qcl3VKxfLWkuxqsx/aBx5F0raS90vzZkraWntvVkiY3WNa70/P8uxVl/FLS3ZJul7Swynbfl3Rbg2Vvr2jLuZImSVol6W2l9W6Q9CeSfp7We1jS5tJ2sxuow2skLZO0IZV7W3pOBl7bq9Pr4T/K77cRlDND0gOSOtN0R5qeJWmOpB+k990qST8aaL+kRaW2rpF0laRXjLQeQPHjFOPxBjxVZV438Kl0fw6wBXj5aJeVpk8FHgWmluZ9DLgFuLmRcoG3A+uB15XKfhj422p1BJ4BHgCmpOlPAd1DlCXgNuAjpXlzgaPT/dtTWxaVlh8L/CDd3x24Bziy4nEfHKjHCNpfsx0V/+uXAbcCxzXwP/691P5d0/QU4BhgQ8V6S4D/U2rbamBGmj4oTd/VrNcb8B3gM+n+7EYfu0pZV6b/a3e1MoDXpjadXpq3F7ARuBvYvxntrJh/BHAn8HJgAXB9xfJFwDea0PZqr/lZwMfLr+00/4vA+Q2W95fARen+t4DzgN2A+4ATS+u9YeB9VtlWYFn5fzGS27jt6Q8lIu4HngY6xqi8K4AbgPeVZi8A/gKYLmnaSB5X0tHAPwF/EBHrS4suAU4d6DlU2EZxQOjsYRR1HPB8RPzjwIyIWB0Rt0h6HfBK4LMUbdpJRGylCIcRtbOGetsxmeLN099AWfsCj0XEswAR8VhE/Bh4QtIRpfVOAZaXpq+k+MCH4rm5vIE6VHMbzX1OXyTplcCRwAeA+dXWiYgNwCeBs0qz3wNcS/E8VN2uERHxc+A/KT7YvwD8WbPLSH4feK7iNf9QRHy9vJIkAa+isdcXwIXAWyR9AjgK+BJwGnBbRKwo1eGuiLi0cmNJuwB7NFqPCRv6kv4ncH9E/GYMi/0FMLCbPAPYJyJuZ8dgGI5dge8DJ0fEPRXLnqII/j+vse1S4LTycMwQ3gCsqrFsIMxuAQ6stpsrqYNi7+ondZZXr8Hacbak1cCvgfsiYnUD5dwAzJB0n6RvSjomzb+cFGyS3gI8njoUA64C/jjd/yOKMGwKSZMo9vJWlGa/rjSssbTBIk4G/j0i7gP60nummhdf18nA6+FyanQC6rR7xfBO+T1yHvAJYFlErGugjMH8D4q21XJ0en09DLyD4v02YhHxPHAORfh/IiKeq6MOUHTuVgOPAJ00+BqbiKF/tqR7gZ9T9BTGUvnXuudThD0UPaKRvDmep+jxfKDG8q8BCyW9unJBRGwBLmPHHtpIzQeWR8QLwPeAPyktO1rSHRRDWz+IiEebUN6LhmjHhRExF9gb2EPSiHudEfEUcBhwBrAZuELSIor/3XvT8YL57NyT7wP6U9l3U+xdNmr39CZ/nOJNfmNp2fqImJtujfaAF/DSXstgr9EXX9eSXgO8Hrg1fVhsk/SGEZa/tdSWuWlvecDbgCcpOiNjQtJSSb+StDLNuiXVawbwbeDvmlDM/6LopFRtl6Sr07Gc75VmX5Fe5/tQDHud00gFJmLoXxgRB1L0rC+TtNsYln0oxRsfijfQIkkPUvTU3iRpzjAf7wWK4YQ3S/qryoUR8QTFGN/Hamz/FYoPjD3qKGsNRejtQNIhFD34G1Nb5rNjONwSEYcAbwQ+KmluHWUN16DtSD2of6cIihGLiO0RcXNELAbOBN4TERspxu6PoRjWuLLKpldQ7JE0a2hna3qTz6IYumr68Iak36EY3rg4/V/PoXjPqMrq5df1qRRDpg+k7WbT5CEeSXtQBOzvA1MlvauZj1+yBnhx7yZ9iL4dqHb9mhU0+PpK743jgbdQdE73rVKHd1OM4+80bBvFoP61jdZjIoY+ABHxPaAH2OnMg9Eg6T3ACcDlkg4E9oiIaRExOyJmUxwIGvabIyKeBv6QYoijWo//y8CHgV2qbNtHEVK19hTKbgJ2lfShgRmS3gx8leIg3+x02w+YJmlWRVn3UbTx0/W1rH5DtSONub6V4mD3iEg6sOJDeS4vXfjvcopd8vUR0Vtl86spQur6kZZfTUQ8SbGH8ylJL2/mYwPvBS6LiFnp/zqD4qD59PJK6cyYvwcGxrkXAPNKr+vDaP64/ueAK9OQ5seAC0ep83YTsJukj5bm1Toz5igae30J+AeKYZ2Hgf9L8bwuA46UdGIddWi4HsC4PnvnBaC3dPskO59RcxhwL/CyUSrrEYqDl/dTvPEPTut3A0sqHuMQYO0wyy2fxTHwpjypSju/TOoIVNnuNRRDDt11lLcfRbiup+iB/BsQwO9WrPdlinA/lh3PcNg9PSf7l+Y9yMjP3qnZjornfw1FMO/ewP/4MIqhtLXAHRTDWANnDU2lGGr7SMU2O7WNJpxhQ8VZLRS9uz9txmOXHvNmivAuzzsLuA7YCvySond/O+lskVT+I6QvdZa2+wVwxAjqsD39/wZuS4CDKc5m2b203teAxaXpRTTh7J30WPtSDG09kNr6I4q9mWMphpdWA7+iOFZ1QAPlnEExTDMwPYniGNoxFMdLfghsoDhwfwPwjlJbN6d63JHW27uRNvsbuWZmGZmwwztmZrYzh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5ll5P8DUfiZjRFdi7QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Algorithms\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "# prepare models\n",
    "n_estimators=50\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', multi_class='auto',max_iter=1000)))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators = n_estimators, random_state = seed)))\n",
    "models.append(('ADA', AdaBoostClassifier(n_estimators=n_estimators, random_state=seed)))\n",
    "models.append(('EXT', ExtraTreesClassifier(n_estimators=n_estimators, random_state=seed)))\n",
    "models.append(('GB', GradientBoostingClassifier(n_estimators=n_estimators, random_state=seed)))\n",
    "models.append(('XGB',XGBClassifier()))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=2, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ExtraTreesClassifier, RandomForest, xGBoost performed the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaseen/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.51      1029\n",
      "           1       0.77      0.73      0.75      8423\n",
      "           2       0.52      0.52      0.52      3872\n",
      "           3       0.47      0.59      0.52      1076\n",
      "           4       0.95      0.97      0.96      1369\n",
      "           5       0.92      0.92      0.92      7146\n",
      "           6       0.59      0.67      0.63      1229\n",
      "           7       0.88      0.88      0.88      4269\n",
      "           8       0.83      0.83      0.83      2526\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     30939\n",
      "   macro avg       0.72      0.73      0.73     30939\n",
      "weighted avg       0.78      0.77      0.77     30939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
